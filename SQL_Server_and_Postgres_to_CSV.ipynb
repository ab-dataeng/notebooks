{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ad880c-a64c-4924-849e-6b017755cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, inspect, MetaData, schema, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327852e8-daf2-4101-86c3-aa9cbb18bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = \"test123\"\n",
    "uid = \"python\"\n",
    "pg_database = 'dvdrental'\n",
    "\n",
    "sql_database = 'BikeStores'\n",
    "mssqlserver_servername = 'DESKTOP-3F6D0VR\\SQLEXPRESS01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b3452d-dbd6-4621-a585-937cc259aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Connections\n",
    "postgres_uri = f\"postgresql+psycopg2://{uid}:{pwd}@localhost:5432/{pg_database}\"\n",
    "postgres_engine = create_engine(postgres_uri)\n",
    "\n",
    "mssqlserver_uri = f\"mssql+pyodbc://{mssqlserver_servername}/{sql_database}?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "mssqlserver_engine = create_engine(mssqlserver_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8030645e-b428-4460-a54e-463d77cd0436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insp = inspect(mssqlserver_engine)\n",
    "insp.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2da3e0-60af-4a84-820b-23a5c828346a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actor',\n",
       " 'store',\n",
       " 'address',\n",
       " 'category',\n",
       " 'city',\n",
       " 'country',\n",
       " 'customer',\n",
       " 'film_actor',\n",
       " 'film_category',\n",
       " 'inventory',\n",
       " 'language',\n",
       " 'rental',\n",
       " 'staff',\n",
       " 'payment',\n",
       " 'film']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insp = inspect(postgres_engine)\n",
    "insp.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb67e9a-3160-404f-bd20-e06fd4f88f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'production', 'sales'}\n"
     ]
    }
   ],
   "source": [
    "# Extracting Schema from MS SQL Server Database\n",
    "mssqlserver_table_query = \"\"\"\n",
    "\n",
    "    SELECT\n",
    "          t.name AS table_name\n",
    "        , s.name AS schema_name\n",
    "    FROM sys.tables t\n",
    "    INNER JOIN sys.schemas s\n",
    "    ON t.schema_id = s.schema_id\n",
    "\n",
    "    UNION\n",
    "\n",
    "    SELECT\n",
    "          v.name AS table_name\n",
    "        , s.name AS schema_name\n",
    "    FROM sys.views v\n",
    "    INNER JOIN sys.schemas s\n",
    "    ON v.schema_id = s.schema_id\n",
    "\n",
    "    ORDER BY schema_name, table_name;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "mssqlserver_connection = mssqlserver_engine.connect()\n",
    "\n",
    "mssqlserver_tables = mssqlserver_connection.execute(text(mssqlserver_table_query))\n",
    "mssqlserver_tables = mssqlserver_tables.fetchall()\n",
    "mssqlserver_tables = dict(mssqlserver_tables)\n",
    "\n",
    "mssqlserver_schemas = set(mssqlserver_tables.values())\n",
    "print(mssqlserver_schemas)\n",
    "\n",
    "mssqlserver_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c73c82-4cc7-4924-8118-308006a0ca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'public'}\n"
     ]
    }
   ],
   "source": [
    "# Extracting Schema from PostgreSQL Database\n",
    "postgres_table_query = \"\"\"\n",
    "\n",
    "    SELECT\n",
    "    table_name,\n",
    "    table_schema\n",
    "FROM\n",
    "    information_schema.tables\n",
    "WHERE\n",
    "    table_schema NOT IN ('information_schema', 'pg_catalog')\n",
    "ORDER BY\n",
    "    table_schema,\n",
    "    table_name;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "postgres_connection = postgres_engine.connect()\n",
    "\n",
    "postgres_tables = postgres_connection.execute(text(postgres_table_query))\n",
    "postgres_tables = postgres_tables.fetchall()\n",
    "postgres_tables = dict(postgres_tables)\n",
    "\n",
    "postgres_schemas = set(postgres_tables.values())\n",
    "print(postgres_schemas)\n",
    "\n",
    "postgres_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159848c9-3a83-4de1-9a66-b704bc208a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Dumping table No. 1 from 9: production.brands...\n",
      "brands table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 2 from 9: production.categories...\n",
      "categories table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 3 from 9: production.products...\n",
      "products table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 4 from 9: production.stocks...\n",
      "stocks table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 5 from 9: sales.customers...\n",
      "customers table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 6 from 9: sales.order_items...\n",
      "order_items table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 7 from 9: sales.orders...\n",
      "orders table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 8 from 9: sales.staffs...\n",
      "staffs table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 9 from 9: sales.stores...\n",
      "stores table is converted to CSV successfully\n"
     ]
    }
   ],
   "source": [
    "# Extracting tables from SQL Server\n",
    "for table_name, schema_name in mssqlserver_tables.items():\n",
    "    \n",
    "    table_no = list(mssqlserver_tables.keys()).index(f\"{table_name}\") + 1\n",
    "    ################################################################\n",
    "    print()\n",
    "    print(f\"##### Dumping table No. {table_no} from {len(mssqlserver_tables)}: {schema_name}.{table_name}...\")\n",
    "    ################################################################\n",
    "    \n",
    "    try:\n",
    "        mssqlserver_connection = mssqlserver_engine.connect()\n",
    "        \n",
    "        full_table = text(f\"\"\"\n",
    "            SELECT\n",
    "            *\n",
    "            FROM {schema_name}.{table_name};\n",
    "        \"\"\")\n",
    "        \n",
    "        df = pd.read_sql(full_table, mssqlserver_connection)\n",
    "        \n",
    "        # Ensure column names are in lowercase to match PostgreSQL's default behavior\n",
    "        df.columns = [c.lower() for c in df.columns]\n",
    "        \n",
    "        # Write to PostgreSQL, specifying the 'public' schema explicitly\n",
    "        df.to_csv(f\"C:/Users/AU TRADERS/BikeStore CSVs/{table_name}.csv\", index=False)\n",
    "        \n",
    "        ################################################################\n",
    "        print(f\"{table_name} table is converted to CSV successfully\")\n",
    "        ################################################################\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {table_name}: {e}\")\n",
    "    finally:\n",
    "        mssqlserver_connection.close()\n",
    "\n",
    "# Dispose of the engines once all operations are complete\n",
    "mssqlserver_engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e112953d-3fd9-4c9e-8492-c13970d63f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Dumping table No. 1 from 22: actor...\n",
      "actor table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 2 from 22: actor_info...\n",
      "actor_info table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 3 from 22: address...\n",
      "address table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 4 from 22: category...\n",
      "category table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 5 from 22: city...\n",
      "city table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 6 from 22: country...\n",
      "country table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 7 from 22: customer...\n",
      "customer table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 8 from 22: customer_list...\n",
      "customer_list table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 9 from 22: film...\n",
      "film table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 10 from 22: film_actor...\n",
      "film_actor table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 11 from 22: film_category...\n",
      "film_category table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 12 from 22: film_list...\n",
      "film_list table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 13 from 22: inventory...\n",
      "inventory table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 14 from 22: language...\n",
      "language table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 15 from 22: nicer_but_slower_film_list...\n",
      "nicer_but_slower_film_list table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 16 from 22: payment...\n",
      "payment table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 17 from 22: rental...\n",
      "rental table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 18 from 22: sales_by_film_category...\n",
      "sales_by_film_category table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 19 from 22: sales_by_store...\n",
      "sales_by_store table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 20 from 22: staff...\n",
      "staff table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 21 from 22: staff_list...\n",
      "staff_list table is converted to CSV successfully\n",
      "\n",
      "##### Dumping table No. 22 from 22: store...\n",
      "store table is converted to CSV successfully\n"
     ]
    }
   ],
   "source": [
    "# dumping tables in 'public' schema of PostgreSQL\n",
    "for table_name, _ in postgres_tables.items():\n",
    "\n",
    "    schema_name = 'cinema'\n",
    "    \n",
    "    table_no = list(postgres_tables.keys()).index(f\"{table_name}\") + 1\n",
    "    ################################################################\n",
    "    print()\n",
    "    print(f\"##### Dumping table No. {table_no} from {len(postgres_tables)}: {table_name}...\")\n",
    "    ################################################################\n",
    "    \n",
    "    try:\n",
    "        postgres_connection = postgres_engine.connect()\n",
    "        \n",
    "        full_table = text(f\"\"\"\n",
    "            SELECT\n",
    "            *\n",
    "            FROM {table_name};\n",
    "        \"\"\")\n",
    "        \n",
    "        df = pd.read_sql(full_table, postgres_connection)\n",
    "        \n",
    "        df.columns = [c.lower() for c in df.columns]\n",
    "        \n",
    "        # Write to PostgreSQL, specifying the 'public' schema explicitly\n",
    "        df.to_csv(f\"C:/Users/AU TRADERS/dvdrental CSVs/{table_name}.csv\", index=False)\n",
    "        \n",
    "        ################################################################\n",
    "        print(f\"{table_name} table is converted to CSV successfully\")\n",
    "        ################################################################\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {table_name}: {e}\")\n",
    "    finally:\n",
    "        postgres_connection.close()\n",
    "\n",
    "postgres_engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c1c640-f7ad-4fda-bcad-7b7bd7d57147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
